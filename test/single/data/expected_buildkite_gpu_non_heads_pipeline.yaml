steps:
- label: ':docker: Build test-gpu-gloo-py3_7-tf1_15_5-keras2_2_4-torch1_8_1-mxnet1_5_1_p0-pyspark3_2_1'
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      build: test-gpu-gloo-py3_7-tf1_15_5-keras2_2_4-torch1_8_1-mxnet1_5_1_p0-pyspark3_2_1
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-gpu-gloo-py3_7-tf1_15_5-keras2_2_4-torch1_8_1-mxnet1_5_1_p0-pyspark3_2_1:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-gpu-gloo-py3_7-tf1_15_5-keras2_2_4-torch1_8_1-mxnet1_5_1_p0-pyspark3_2_1-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 40
  retry:
    automatic: true
  agents:
    queue: cpu-v572
- label: ':docker: Build test-gpu-gloo-py3_8-tf2_6_3-keras2_6_0-torch1_9_1-mxnet1_7_0_p1-pyspark3_2_1'
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      build: test-gpu-gloo-py3_8-tf2_6_3-keras2_6_0-torch1_9_1-mxnet1_7_0_p1-pyspark3_2_1
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-gpu-gloo-py3_8-tf2_6_3-keras2_6_0-torch1_9_1-mxnet1_7_0_p1-pyspark3_2_1:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-gpu-gloo-py3_8-tf2_6_3-keras2_6_0-torch1_9_1-mxnet1_7_0_p1-pyspark3_2_1-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 40
  retry:
    automatic: true
  agents:
    queue: cpu-v572
- label: ':docker: Build test-gpu-gloo-py3_8-tf2_7_1-keras2_7_0-torch1_10_2-mxnet1_8_0_p0-pyspark3_2_1'
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      build: test-gpu-gloo-py3_8-tf2_7_1-keras2_7_0-torch1_10_2-mxnet1_8_0_p0-pyspark3_2_1
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-gpu-gloo-py3_8-tf2_7_1-keras2_7_0-torch1_10_2-mxnet1_8_0_p0-pyspark3_2_1:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-gpu-gloo-py3_8-tf2_7_1-keras2_7_0-torch1_10_2-mxnet1_8_0_p0-pyspark3_2_1-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 40
  retry:
    automatic: true
  agents:
    queue: cpu-v572
- label: ':docker: Build test-gpu-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1'
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      build: test-gpu-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-gpu-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-gpu-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 40
  retry:
    automatic: true
  agents:
    queue: cpu-v572
- label: ':docker: Build test-gpu-gloo-py3_7-tfmin-kerasmin-torchmin-mxnetmin-pysparkmin'
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      build: test-gpu-gloo-py3_7-tfmin-kerasmin-torchmin-mxnetmin-pysparkmin
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-gpu-gloo-py3_7-tfmin-kerasmin-torchmin-mxnetmin-pysparkmin:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-gpu-gloo-py3_7-tfmin-kerasmin-torchmin-mxnetmin-pysparkmin-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 40
  retry:
    automatic: true
  agents:
    queue: cpu-v572
- label: ':docker: Build test-mixed-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1'
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      build: test-mixed-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1
      image-repository: 823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite
      cache-from: test-mixed-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1:823773083436.dkr.ecr.us-east-1.amazonaws.com/buildkite:SLUG-test-mixed-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1-latest
      config: docker-compose.test.yml
      push-retries: 5
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 40
  retry:
    automatic: true
  agents:
    queue: cpu-v572
- wait
- wait
- wait
- label: ':tensorflow: Gloo TensorFlow 2.0 MNIST Data Service (test-gpu-gloo-py3_8-tf2_6_3-keras2_6_0-torch1_9_1-mxnet1_7_0_p1-pyspark3_2_1)'
  command: bash -c "horovodrun -np 2 python -m horovod.tensorflow.data.compute_worker /tmp/compute.json & horovodrun -np 2 --gloo python /horovod/examples/tensorflow2/tensorflow2_mnist_data_service.py /tmp/compute.json"
  artifact_paths: "artifacts/**"
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      run: test-gpu-gloo-py3_8-tf2_6_3-keras2_6_0-torch1_9_1-mxnet1_7_0_p1-pyspark3_2_1
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 10
  retry:
    automatic: true
  agents:
    queue: 2x-gpu-v572
- label: ':spark: Spark TensorFlow 2.0 MNIST Data Service (test-gpu-gloo-py3_8-tf2_6_3-keras2_6_0-torch1_9_1-mxnet1_7_0_p1-pyspark3_2_1)'
  command: bash -c "cd /horovod/examples/spark/tensorflow2; worker_py=\"\\$(python -c \"import horovod.spark.tensorflow.compute_worker as worker; print(worker.__file__)\")\"; spark-submit --master \"local[2]\" \"\\$worker_py\" /tmp/compute.json & OMP_NUM_THREADS=1 /spark_env.sh spark-submit --master \"local[2]\" --py-files tensorflow2_mnist_data_service_train_fn_compute_side_dispatcher.py,tensorflow2_mnist_data_service_train_fn_training_side_dispatcher.py tensorflow2_mnist_data_service.py /tmp/compute.json"
  artifact_paths: "artifacts/**"
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      run: test-gpu-gloo-py3_8-tf2_6_3-keras2_6_0-torch1_9_1-mxnet1_7_0_p1-pyspark3_2_1
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 10
  retry:
    automatic: true
  agents:
    queue: 2x-gpu-v572
- label: ':tensorflow: Gloo TensorFlow 2.0 MNIST Data Service (test-gpu-gloo-py3_8-tf2_7_1-keras2_7_0-torch1_10_2-mxnet1_8_0_p0-pyspark3_2_1)'
  command: bash -c "horovodrun -np 2 python -m horovod.tensorflow.data.compute_worker /tmp/compute.json & horovodrun -np 2 --gloo python /horovod/examples/tensorflow2/tensorflow2_mnist_data_service.py /tmp/compute.json"
  artifact_paths: "artifacts/**"
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      run: test-gpu-gloo-py3_8-tf2_7_1-keras2_7_0-torch1_10_2-mxnet1_8_0_p0-pyspark3_2_1
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 10
  retry:
    automatic: true
  agents:
    queue: 2x-gpu-v572
- label: ':spark: Spark TensorFlow 2.0 MNIST Data Service (test-gpu-gloo-py3_8-tf2_7_1-keras2_7_0-torch1_10_2-mxnet1_8_0_p0-pyspark3_2_1)'
  command: bash -c "cd /horovod/examples/spark/tensorflow2; worker_py=\"\\$(python -c \"import horovod.spark.tensorflow.compute_worker as worker; print(worker.__file__)\")\"; spark-submit --master \"local[2]\" \"\\$worker_py\" /tmp/compute.json & OMP_NUM_THREADS=1 /spark_env.sh spark-submit --master \"local[2]\" --py-files tensorflow2_mnist_data_service_train_fn_compute_side_dispatcher.py,tensorflow2_mnist_data_service_train_fn_training_side_dispatcher.py tensorflow2_mnist_data_service.py /tmp/compute.json"
  artifact_paths: "artifacts/**"
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      run: test-gpu-gloo-py3_8-tf2_7_1-keras2_7_0-torch1_10_2-mxnet1_8_0_p0-pyspark3_2_1
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 10
  retry:
    automatic: true
  agents:
    queue: 2x-gpu-v572
- label: ':tensorflow: Gloo TensorFlow 2.0 MNIST Data Service (test-gpu-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1)'
  command: bash -c "horovodrun -np 2 python -m horovod.tensorflow.data.compute_worker /tmp/compute.json & horovodrun -np 2 --gloo python /horovod/examples/tensorflow2/tensorflow2_mnist_data_service.py /tmp/compute.json"
  artifact_paths: "artifacts/**"
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      run: test-gpu-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 10
  retry:
    automatic: true
  agents:
    queue: 2x-gpu-v572
- label: ':tensorflow: MPI TensorFlow 2.0 MNIST Data Service (test-gpu-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1)'
  command: bash -c " horovodrun -np 2 python -m horovod.tensorflow.data.compute_worker /tmp/compute.json & horovodrun -np 2 --mpi python /horovod/examples/tensorflow2/tensorflow2_mnist_data_service.py /tmp/compute.json"
  artifact_paths: "artifacts/**"
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      run: test-gpu-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 10
  retry:
    automatic: true
  agents:
    queue: 2x-gpu-v572
- label: ':spark: Spark TensorFlow 2.0 MNIST Data Service (test-gpu-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1)'
  command: bash -c "cd /horovod/examples/spark/tensorflow2; worker_py=\"\\$(python -c \"import horovod.spark.tensorflow.compute_worker as worker; print(worker.__file__)\")\"; spark-submit --master \"local[2]\" \"\\$worker_py\" /tmp/compute.json & OMP_NUM_THREADS=1 /spark_env.sh spark-submit --master \"local[2]\" --py-files tensorflow2_mnist_data_service_train_fn_compute_side_dispatcher.py,tensorflow2_mnist_data_service_train_fn_training_side_dispatcher.py tensorflow2_mnist_data_service.py /tmp/compute.json"
  artifact_paths: "artifacts/**"
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      run: test-gpu-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 10
  retry:
    automatic: true
  agents:
    queue: 2x-gpu-v572
- label: ':tensorflow: Gloo TensorFlow 2.0 MNIST Data Service (test-mixed-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1)'
  command: bash -c "horovodrun -np 2 python -m horovod.tensorflow.data.compute_worker /tmp/compute.json & horovodrun -np 2 --gloo python /horovod/examples/tensorflow2/tensorflow2_mnist_data_service.py /tmp/compute.json"
  artifact_paths: "artifacts/**"
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      run: test-mixed-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 10
  retry:
    automatic: true
  agents:
    queue: 2x-gpu-v572
- label: ':tensorflow: MPI TensorFlow 2.0 MNIST Data Service (test-mixed-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1)'
  command: bash -c " horovodrun -np 2 python -m horovod.tensorflow.data.compute_worker /tmp/compute.json & horovodrun -np 2 --mpi python /horovod/examples/tensorflow2/tensorflow2_mnist_data_service.py /tmp/compute.json"
  artifact_paths: "artifacts/**"
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      run: test-mixed-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 10
  retry:
    automatic: true
  agents:
    queue: 2x-gpu-v572
- label: ':spark: Spark TensorFlow 2.0 MNIST Data Service (test-mixed-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1)'
  command: bash -c "cd /horovod/examples/spark/tensorflow2; worker_py=\"\\$(python -c \"import horovod.spark.tensorflow.compute_worker as worker; print(worker.__file__)\")\"; spark-submit --master \"local[2]\" \"\\$worker_py\" /tmp/compute.json & OMP_NUM_THREADS=1 /spark_env.sh spark-submit --master \"local[2]\" --py-files tensorflow2_mnist_data_service_train_fn_compute_side_dispatcher.py,tensorflow2_mnist_data_service_train_fn_training_side_dispatcher.py tensorflow2_mnist_data_service.py /tmp/compute.json"
  artifact_paths: "artifacts/**"
  env:
    COMPOSE_HTTP_TIMEOUT: 300
  plugins:
  - docker-compose#v3.5.0:
      run: test-mixed-openmpi-gloo-py3_8-tf2_8_0-keras2_8_0-torch1_11_0-mxnet1_9_0-pyspark3_2_1
      volumes: "./artifacts:/artifacts"
      config: docker-compose.test.yml
      pull-retries: 3
  - ecr#v1.2.0:
      login: true
  timeout_in_minutes: 10
  retry:
    automatic: true
  agents:
    queue: 2x-gpu-v572
