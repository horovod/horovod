30c30
< parser = argparse.ArgumentParser(description='Keras Spark Rossmann Run Example',
---
> parser = argparse.ArgumentParser(description='Keras Spark3 Rossmann Run Example',
36c36
< parser.add_argument('--training-master',
---
> parser.add_argument('--training-master', default='local-cluster[2,1,1024]',
60a61,63
>     # Location of discovery script on local filesystem.
>     DISCOVERY_SCRIPT = 'get_gpu_resources.sh'
> 
63a67,72
>     # Whether to infer on GPU.
>     GPU_INFERENCE_ENABLED = False
> 
>     # Cluster for GPU inference.
>     GPU_INFERENCE_CLUSTER = 'local-cluster[2,1,1024]'  # or 'spark://hostname:7077'
> 
397a407
>         from horovod.spark.task import get_available_devices
412c422
<         config.gpu_options.visible_device_list = str(hvd.local_rank())
---
>         config.gpu_options.visible_device_list = get_available_devices()[0]
495a506,530
>     def set_gpu_conf(conf):
>         # This config will change depending on your cluster setup.
>         #
>         # 1. Standalone Cluster
>         # - Must configure spark.worker.* configs as below.
>         #
>         # 2. YARN
>         # - Requires YARN 3.1 or higher to support GPUs
>         # - Cluster should be configured to have isolation on so that
>         #   multiple executors don’t see the same GPU on the same host.
>         # - If you don’t have isolation then you would require a different discovery script
>         #   or other way to make sure that 2 executors don’t try to use same GPU.
>         #
>         # 3. Kubernetes
>         # - Requires GPU support and isolation.
>         # - Add conf.set(“spark.executor.resource.gpu.discoveryScript”, DISCOVERY_SCRIPT)
>         # - Add conf.set(“spark.executor.resource.gpu.vendor”, “nvidia.com”)
>         conf = conf.set("spark.test.home", os.environ.get('SPARK_HOME'))
>         conf = conf.set("spark.worker.resource.gpu.discoveryScript", DISCOVERY_SCRIPT)
>         conf = conf.set("spark.worker.resource.gpu.amount", 1)
>         conf = conf.set("spark.task.resource.gpu.amount", "1")
>         conf = conf.set("spark.executor.resource.gpu.amount", "1")
>         return conf
> 
> 
499a535
>     conf = set_gpu_conf(conf)
530,531c566,574
<     if args.processing_master:
<         conf.setMaster(args.processing_master)
---
> 
>     if GPU_INFERENCE_ENABLED:
>         if GPU_INFERENCE_CLUSTER:
>             conf.setMaster(GPU_INFERENCE_CLUSTER)
>         conf = set_gpu_conf(conf)
>     else:
>         if args.processing_master:
>             conf.setMaster(args.processing_master)
> 
541,545c584,595
<             # Do not use GPUs for prediction, use single CPU core per task.
<             config = tf.ConfigProto(device_count={'GPU': 0})
<             config.inter_op_parallelism_threads = 1
<             config.intra_op_parallelism_threads = 1
<             K.set_session(tf.Session(config=config))
---
>             if GPU_INFERENCE_ENABLED:
>                 from pyspark import TaskContext
>                 config = tf.ConfigProto()
>                 config.gpu_options.allow_growth = True
>                 config.gpu_options.visible_device_list = TaskContext.get().resources()['gpu'].addresses[0]
>                 K.set_session(tf.Session(config=config))
>             else:
>                 # Do not use GPUs for prediction, use single CPU core per task.
>                 config = tf.ConfigProto(device_count={'GPU': 0})
>                 config.inter_op_parallelism_threads = 1
>                 config.intra_op_parallelism_threads = 1
>                 K.set_session(tf.Session(config=config))
